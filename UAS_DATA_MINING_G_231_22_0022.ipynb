{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "METODE UNSUPERVISED"
      ],
      "metadata": {
        "id": "HKNaSoJK0bgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKiKqKGd0ZmB"
      },
      "outputs": [],
      "source": [
        "# unsupervised_learning.py\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)\n",
        "\n",
        "# Visualize the clusters\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75)\n",
        "plt.xlabel(iris.feature_names[0])\n",
        "plt.ylabel(iris.feature_names[1])\n",
        "plt.title('K-Means Clustering of Iris Dataset')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METODE SUPERVISED"
      ],
      "metadata": {
        "id": "fQ1P7kpJ0mPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# supervised_learning_random_forest.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "# Ensure the Google Sheets document is shared publicly and use the appropriate CSV export link\n",
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRwXLbV0s5_OA7jQILyGCAhDXwJHrQM2FzUcEUhIrwLCKRcgo5aCTMhaNnaMIzXKA/pub?output=csv'\n",
        "series = pd.read_csv(url, header=0, index_col=0, parse_dates=True)\n",
        "\n",
        "# Ensure the index is a DatetimeIndex\n",
        "series.index = pd.to_datetime(series.index)\n",
        "\n",
        "# Convert the index to a PeriodIndex\n",
        "series.index = series.index.to_period('M')\n",
        "series = series.squeeze()\n",
        "\n",
        "# Prepare the data\n",
        "X = np.array(range(len(series))).reshape(-1, 1)  # Time periods as features\n",
        "y = series.values  # Passenger counts\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "9fdHdaND0oex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}